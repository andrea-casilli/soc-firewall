# SOC Firewall Continuous Integration Pipeline
# Runs on every push and pull request
# Version: 1.0.0

name: CI Pipeline

on:
  push:
    branches: [ main, develop, feature/*, release/* ]
    paths-ignore:
      - 'docs/**'
      - '**.md'
      - '.gitignore'
      - 'LICENSE'
  
  pull_request:
    branches: [ main, develop ]
    paths-ignore:
      - 'docs/**'
      - '**.md'
  
  workflow_dispatch:  # Manual trigger
    inputs:
      test_level:
        description: 'Test level (basic/full)'
        required: true
        default: 'full'
        type: choice
        options:
          - basic
          - full

# Concurrency control
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Environment variables
env:
  PYTHON_VERSION: '3.11'
  POETRY_VERSION: '1.7.1'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Validate code style and formatting
  lint:
    name: Lint and Style Check
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black==23.12.1 isort==5.13.2 flake8==7.0.0 mypy==1.8.0 pylint==3.0.3
          pip install -r requirements/development.txt
      
      - name: Check formatting with Black
        run: black --check src/ tests/
      
      - name: Check imports with isort
        run: isort --check-only src/ tests/
      
      - name: Lint with flake8
        run: flake8 src/ tests/ --count --statistics
      
      - name: Type check with mypy
        run: mypy src/ --ignore-missing-imports
      
      - name: Lint with pylint
        run: pylint src/ --fail-under=8.0
      
      - name: Security lint with bandit
        run: bandit -r src/ -f json -o bandit-report.json
      
      - name: Upload bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: bandit-report.json

  # Run unit tests
  unit-tests:
    name: Unit Tests
    needs: lint
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libpcap-dev build-essential
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-xdist pytest-mock
          pip install -r requirements/development.txt
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ \
            -v \
            --cov=src \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --junitxml=test-results.xml \
            -n auto
      
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-${{ matrix.python-version }}
          path: htmlcov/
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.python-version }}
          path: test-results.xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  # Run integration tests
  integration-tests:
    name: Integration Tests
    needs: lint
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libpcap-dev build-essential iptables
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-xdist
          pip install -r requirements/development.txt
      
      - name: Set up test environment
        run: |
          sudo ip link add dummy0 type dummy 2>/dev/null || true
          sudo ip addr add 192.168.100.1/24 dev dummy0 2>/dev/null || true
          sudo ip link set dummy0 up
      
      - name: Run integration tests
        run: |
          pytest tests/integration/ \
            -v \
            --cov=src --cov-append \
            --cov-report=xml \
            --cov-report=term \
            --junitxml=integration-results.xml
      
      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-results
          path: integration-results.xml
      
      - name: Clean up test environment
        if: always()
        run: |
          sudo ip link delete dummy0 2>/dev/null || true

  # Run performance tests
  performance-tests:
    name: Performance Tests
    needs: [unit-tests, integration-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-benchmark psutil locust
          pip install -r requirements/development.txt
      
      - name: Run performance benchmarks
        run: |
          pytest tests/performance/test_performance.py \
            -v \
            --benchmark-only \
            --benchmark-json=benchmark-results.json
      
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json
      
      - name: Run load tests
        run: |
          locust -f tests/performance/locustfile.py \
            --headless \
            --users 100 \
            --spawn-rate 10 \
            --run-time 5m \
            --host http://localhost:5000 \
            --csv load-test-results \
            --only-summary
      
      - name: Upload load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: load-test-results*.csv

  # Security scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install safety bandit pip-audit
      
      - name: Check dependencies with safety
        run: safety check -r requirements/production.txt --json > safety-report.json || true
      
      - name: Upload safety report
        uses: actions/upload-artifact@v4
        with:
          name: safety-report
          path: safety-report.json
      
      - name: Audit dependencies with pip-audit
        run: pip-audit -r requirements/production.txt --format json > pip-audit-report.json || true
      
      - name: Upload pip-audit report
        uses: actions/upload-artifact@v4
        with:
          name: pip-audit-report
          path: pip-audit-report.json
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  # Build and test Docker image
  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [unit-tests, integration-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          target: production
          push: false
          load: true
          tags: soc-firewall:test
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Test Docker image
        run: |
          docker run --rm soc-firewall:test python -c "import src; print('Docker image OK')"
      
      - name: Scan Docker image for vulnerabilities
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'soc-firewall:test'
          format: 'sarif'
          output: 'docker-trivy-results.sarif'
      
      - name: Upload Docker scan results
        uses: actions/upload-artifact@v4
        with:
          name: docker-scan-results
          path: docker-trivy-results.sarif

  # Code quality report
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install radon xenon pylint
      
      - name: Calculate code metrics with Radon
        run: |
          radon cc src/ -s -j > radon-cc.json
          radon mi src/ -s -j > radon-mi.json
      
      - name: Upload radon reports
        uses: actions/upload-artifact@v4
        with:
          name: radon-reports
          path: radon-*.json
      
      - name: Check maintainability index
        run: xenon src/ --max-absolute B --max-modules B --max-average A
      
      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@master
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # Dependency review
  dependency-review:
    name: Dependency Review
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Dependency Review
        uses: actions/dependency-review-action@v4
        with:
          fail-on-severity: high
          allow-licenses: MIT, Apache-2.0, BSD-3-Clause

  # Final status check
  ci-status:
    name: CI Status
    runs-on: ubuntu-latest
    needs: [lint, unit-tests, integration-tests, security-scan, docker-build, code-quality]
    if: always()
    
    steps:
      - name: Check all jobs passed
        run: |
          echo "Lint: ${{ needs.lint.result }}"
          echo "Unit Tests: ${{ needs.unit-tests.result }}"
          echo "Integration Tests: ${{ needs.integration-tests.result }}"
          echo "Security Scan: ${{ needs.security-scan.result }}"
          echo "Docker Build: ${{ needs.docker-build.result }}"
          echo "Code Quality: ${{ needs.code-quality.result }}"
          
          if [ "${{ needs.lint.result }}" = "success" ] && \
             [ "${{ needs.unit-tests.result }}" = "success" ] && \
             [ "${{ needs.integration-tests.result }}" = "success" ] && \
             [ "${{ needs.security-scan.result }}" = "success" ] && \
             [ "${{ needs.docker-build.result }}" = "success" ] && \
             [ "${{ needs.code-quality.result }}" = "success" ]; then
            echo "✅ All CI checks passed"
            exit 0
          else
            echo "❌ Some CI checks failed"
            exit 1
          fi
      
      - name: Create status badge
        if: success()
        run: |
          echo "![CI Status](https://img.shields.io/github/actions/workflow/status/${{ github.repository }}/ci.yml?branch=main)" > ci-badge.txt

  # Notify on failure
  notify-failure:
    name: Notify Failure
    runs-on: ubuntu-latest
    needs: [ci-status]
    if: failure() && github.ref == 'refs/heads/main'
    
    steps:
      - name: Send Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          fields: repo,message,commit,author,action,eventName,ref,workflow
          mention: here
          if_mention: failure
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      
      - name: Send email notification
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "CI Pipeline Failed: ${{ github.repository }}"
          to: security-team@example.com
          from: GitHub Actions
          body: |
            CI Pipeline failed for ${{ github.repository }}
            
            Commit: ${{ github.sha }}
            Author: ${{ github.actor }}
            Branch: ${{ github.ref }}
            
            See: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
